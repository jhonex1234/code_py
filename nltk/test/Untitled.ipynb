{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sit= [40,70,70]\n",
    "a=len(sit)**len(sit)\n",
    "b,c,d,f=0,0,0,0\n",
    "lista=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   [51, 79, 64]\n",
      "2   [35, 54, 30]\n",
      "3   [54, 69, 65]\n",
      "4   [52, 67, 40]\n",
      "5   [49, 70, 50]\n",
      "6   [48, 42, 60]\n",
      "7   [43, 77, 34]\n",
      "8   [30, 42, 42]\n",
      "9   [57, 75, 47]\n",
      "10   [40, 62, 63]\n",
      "11   [56, 76, 65]\n",
      "12   [34, 61, 61]\n",
      "13   [40, 54, 69]\n",
      "14   [30, 71, 33]\n",
      "15   [49, 47, 32]\n",
      "16   [45, 60, 65]\n",
      "17   [33, 75, 68]\n",
      "18   [47, 44, 48]\n",
      "19   [35, 47, 47]\n",
      "20   [48, 44, 67]\n",
      "21   [31, 72, 36]\n",
      "22   [54, 57, 65]\n",
      "23   [55, 55, 65]\n",
      "24   [52, 79, 42]\n",
      "25   [40, 53, 52]\n",
      "26   [47, 51, 30]\n",
      "27   [58, 60, 54]\n"
     ]
    }
   ],
   "source": [
    "while a>0:\n",
    "    d=d+1\n",
    "    b,c,f=int(random.uniform(40,80)),int(random.uniform(30,70)),int(random.uniform(30,60))\n",
    "    lista.append([f,b,c])\n",
    "    print(d,' ',[f,b,c])\n",
    "    a=a-1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.externals import joblib\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StateMachineError(Exception):\n",
    "    pass\n",
    "\n",
    "class ChatbotError(Exception):\n",
    "    pass\n",
    "\n",
    "# http://www.quesucede.com/page/show/id/python-3-tree-implementation\n",
    "# Brett Kromkamp (brett@perfectlearn.com)\n",
    "# You Programming (http://www.youprogramming.com)\n",
    "# May 03, 2014\n",
    "\n",
    "class State:\n",
    "    def __init__(self, vectorizer, model):\n",
    "        self.__vectorizer = vectorizer\n",
    "        self.__model = model\n",
    "        self.__transitions = {}\n",
    "\n",
    "    @property\n",
    "    def vectorizer(self):\n",
    "        return self.__vectorizer\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.__model\n",
    "\n",
    "    @property\n",
    "    def transitions(self):\n",
    "        return self.__transitions\n",
    "\n",
    "    @transitions.setter\n",
    "    def transitions(self, transitions):\n",
    "        self.__transitions.update(transitions)\n",
    "\n",
    "class StateMachine:\n",
    "    def __init__(self, num_intents):\n",
    "        self.__states = {}\n",
    "        self.__current_state = ''\n",
    "        self.__num_intents = num_intents\n",
    "        self.__intent = 0\n",
    "\n",
    "    @property\n",
    "    def current_state(self):\n",
    "        return self.__current_state\n",
    "\n",
    "    @current_state.setter\n",
    "    def current_state(self, value):\n",
    "        self.__current_state = value\n",
    "\n",
    "    @property\n",
    "    def intent(self):\n",
    "        return self.__intent\n",
    "\n",
    "    @intent.setter\n",
    "    def intent(self, value):\n",
    "        self.__intent = value\n",
    "        \n",
    "    def add_state(self, identifier, vectorizer, model):\n",
    "        if identifier not in self.__states:\n",
    "            self.__states[identifier] = State(vectorizer, model)\n",
    "        else:\n",
    "            raise StateMachineError('Este estado ya esta definido')\n",
    "\n",
    "    def add_transitions(self, state, transitions):\n",
    "        if state in self.__states:\n",
    "            undefined_states = set(transitions.values()) - set(self.__states.keys())\n",
    "            if not undefined_states:\n",
    "                undefined_labels = set(transitions.keys()) - set(self.__states[state].model.classes_)\n",
    "                if not undefined_labels:\n",
    "                    self.__states[state].transitions = transitions\n",
    "                else:\n",
    "                    raise StateMachineError('Las etiquetas {0} no estan definidas en el modelo del estado {1}'\n",
    "                                    .format(undefined_labels, state))\n",
    "            else:\n",
    "                raise StateMachineError('Los estados {0} no estan definidos'.format(undefined_states))\n",
    "        else:\n",
    "            raise StateMachineError('El estado {0} no esta definido'.format(state))\n",
    "\n",
    "    def add_initial_state(self, identifier):\n",
    "        if identifier in self.__states:\n",
    "            if not self.__current_state:\n",
    "                self.__current_state = identifier\n",
    "            else:\n",
    "                raise StateMachineError('Ya se definio un estado inicial')\n",
    "        else:\n",
    "            raise StateMachineError('Este estado no esta definido')\n",
    "    def __clear_message(self, text):\n",
    "        exception_words = ['formulario', 'continuidad']\n",
    "\n",
    "        stemmer = SnowballStemmer('spanish')\n",
    "        words = tokenize.word_tokenize(str(text))\n",
    "        norm_words = [normalize('NFKD', word.lower()).encode('ascii', 'ignore').decode('utf-8')\n",
    "                      for word in words]\n",
    "        clean_words = [stemmer.stem(word) if word not in exception_words else word\n",
    "                       for word in norm_words if word.isalpha() and re.search('[aeiou]', word)\n",
    "                       and re.search('[bcdfghjklmnpqrstvwxyz]', word)]\n",
    "        return ' '.join(clean_words)\n",
    "\n",
    "    def transition(self, message):\n",
    "        if self.__states:\n",
    "            if self.__current_state:\n",
    "                clean_message = self.__clear_message(message)\n",
    "                features = self.__states[self.__current_state].vectorizer.transform([clean_message])\n",
    "                predict = self.__states[self.__current_state].model.predict(features)[0]\n",
    "                current_state_proba = self.__states[self.__current_state].model.predict_proba(features).max()\n",
    "                transitions = self.__states[self.__current_state].transitions\n",
    "                if self.__current_state == transitions[predict]:\n",
    "                    if self.__intent >= self.__num_intents:\n",
    "                        self.__intent = 0\n",
    "                        self.__current_state = 's1'\n",
    "                        return ('agente', -1, -1)\n",
    "                    else:\n",
    "                        self.__intent += 1\n",
    "                else:\n",
    "                    self.__intent = 0\n",
    "                self.__current_state = transitions[predict]\n",
    "                features = self.__states[self.__current_state].vectorizer.transform([clean_message])\n",
    "                next_state_proba = self.__states[self.__current_state].model.predict_proba(features).max()\n",
    "                return (predict, np.around(current_state_proba * 100, 0), np.around(next_state_proba * 100, 0))\n",
    "            else:\n",
    "                raise StateMachineError('El estado inicial no se ha definido')\n",
    "        else:\n",
    "            raise StateMachineError('Aun no hay estados definidos')\n",
    "\n",
    "\n",
    "    def load_params(self, filepath):\n",
    "        with open(filepath, 'r') as jsonfile:\n",
    "            params = json.load(jsonfile)\n",
    "            self.__current_state = params['current_state']\n",
    "            self.__intent = params['intent']\n",
    "            \n",
    "    def save_params(self, filepath):\n",
    "        with open(filepath, 'w') as jsonfile:\n",
    "            params = {'current_state': self.__current_state, 'intent': self.__intent}\n",
    "            json.dump(params, jsonfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, config_section):\n",
    "        self.__config_section = config_section\n",
    "        self.__session_id = ''\n",
    "\n",
    "        models = joblib.load(config_section['path'] + config_section['trained_package'])\n",
    "\n",
    "        dialog_tree = StateMachine(0)\n",
    "\n",
    "        for model in models:\n",
    "            dialog_tree.add_state(model['state'], model['vectorizer'], model['classifier'])\n",
    "\n",
    "        dialog_tree.add_transitions('s1', {'saludo': 's2', 'otro': 's2'})\n",
    "        dialog_tree.add_transitions('s2', {'fusion': 's4', 'inscripcion': 's3', 'otro': 's2'})\n",
    "        dialog_tree.add_transitions('s3', {'primera vez': 's4', 'continuidad': 's4', 'perdida': 's4', 'otro': 's3'})\n",
    "        dialog_tree.add_transitions('s4', {'costo': 's5', 'procedimiento': 's5'})\n",
    "        dialog_tree.add_transitions('s5', {'positivo': 's2', 'negativo': 's2'})\n",
    "\n",
    "        dialog_tree.add_initial_state('s1')\n",
    "        self.__dialog_tree = dialog_tree\n",
    "        self.__topic = 'none'\n",
    "\n",
    "    def get_answer(self, input_message):\n",
    "        with open(self.__config_section['path'] + self.__config_section['templates_file'], 'r') as jsonfile:\n",
    "            templates = json.load(jsonfile)\n",
    "\n",
    "        proba = []\n",
    "        if input_message != '':\n",
    "            flow = True\n",
    "            while flow:\n",
    "                previous_state = self.__dialog_tree.current_state\n",
    "                label, current_state_proba, next_state_proba = self.__dialog_tree.transition(input_message)\n",
    "                if previous_state == 's1' and label == 'otro':\n",
    "                    previous_state = self.__dialog_tree.current_state\n",
    "                    label, current_state_proba, next_state_proba = self.__dialog_tree.transition(input_message)\n",
    "                if previous_state == 's5' and label == 'positivo':\n",
    "                    previous_state = self.__dialog_tree.current_state\n",
    "                    label, current_state_proba, next_state_proba = self.__dialog_tree.transition(input_message)\n",
    "                current_state = self.__dialog_tree.current_state\n",
    "                proba.append((current_state_proba, next_state_proba))\n",
    "\n",
    "                if (previous_state == 's2' or previous_state == 's3'):\n",
    "                    self.__topic = label\n",
    "\n",
    "                flow = ((previous_state == 's2' and current_state == 's3' and next_state_proba > 37) or \n",
    "                        (previous_state == 's2' and current_state == 's4' and next_state_proba > 64) or\n",
    "                        (previous_state == 's3' and current_state == 's4' and next_state_proba > 63))\n",
    "\n",
    "            output = [(item['message'], item['length']) for item in templates \n",
    "                      if item['state'] == previous_state and item['label'] == label\n",
    "                      and item['topic'] == self.__topic]\n",
    "            if output:\n",
    "                message, length = output[0]\n",
    "                transfer = label == 'agente'\n",
    "            else:\n",
    "                raise ChatbotError('No hay ninguna plantilla definida para el estado, etiqueta o tema que se esta intentando buscar')\n",
    "\n",
    "            if label == 'agente':\n",
    "                self.__topic = 'none'\n",
    "                \n",
    "            with open(self.__config_section['path'] + self.__config_section['sessions_file'], 'r') as jsonfile:\n",
    "                sessions_id = json.load(jsonfile)\n",
    "            sessions_id[self.__session_id] = (self.__dialog_tree.current_state, self.__dialog_tree.intent, self.__topic)\n",
    "            with open(self.__config_section['path'] + self.__config_section['sessions_file'], 'w') as jsonfile:\n",
    "                json.dump(sessions_id, jsonfile)\n",
    "        else:\n",
    "            proba.append((-1, -1))\n",
    "            message, length = ('not answer', [2])\n",
    "            transfer = False\n",
    "        \n",
    "        return (proba, message, length, transfer)\n",
    "\n",
    "    def session(self, session_id, is_session_active):\n",
    "        self.__session_id = session_id\n",
    "\n",
    "        with open(self.__config_section['path'] + self.__config_section['sessions_file'], 'r') as jsonfile:\n",
    "            sessions_id = json.load(jsonfile)\n",
    "\n",
    "        if is_session_active:\n",
    "            if session_id in sessions_id:\n",
    "                self.__dialog_tree.current_state, self.__dialog_tree.intent, self.__topic = sessions_id[session_id]\n",
    "        else:\n",
    "            if session_id in sessions_id:                \n",
    "                sessions_id.pop(session_id)\n",
    "                with open(self.__config_section['path'] + self.__config_section['sessions_file'], 'w') as jsonfile:\n",
    "                    json.dump(sessions_id, jsonfile)\n",
    "            else:\n",
    "                raise ChatbotError('session_id no puede eliminarse porque no existe')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.externals.joblib.numpy_pickle' has no attribute 'NumpyArrayWrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-af38a19aad72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainedpackage.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positivo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# More user-friendly error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.externals.joblib.numpy_pickle' has no attribute 'NumpyArrayWrapper'"
     ]
    }
   ],
   "source": [
    "    models = joblib.load('trainedpackage.pkl')\n",
    "    model = next(model for model in models if model['state'] == 's3')\n",
    "    model['classifier'].classes_\n",
    "    vocabulary(model['vectorizer'], model['classifier'], 'positivo', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.externals.joblib.numpy_pickle' has no attribute 'NumpyArrayWrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-af38a19aad72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainedpackage.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'positivo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# More user-friendly error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.externals.joblib.numpy_pickle' has no attribute 'NumpyArrayWrapper'"
     ]
    }
   ],
   "source": [
    "models = joblib.load('trainedpackage.pkl')\n",
    "model = next(model for model in models if model['state'] == 's3')\n",
    "model['classifier'].classes_\n",
    "vocabulary(model['vectorizer'], model['classifier'], 'positivo', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
